{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8A8ucsHG4JWUOOaG+gc6u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dadashzadeh/Keyword-Suggestion-Tool/blob/main/wikipedia/wikipedia_graph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!!pip install httpx\n",
        "!!pip install pyvis\n",
        "!!pip install networkx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7X8t4CQm7Bo",
        "outputId": "587eb813-92f9-4ec9-9f2b-2737ee438aa2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (3.4.2)']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import httpx\n",
        "import networkx as nx\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from pyvis.network import Network\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "jTQl7LjyFAWB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "async def fetch_search_results(query: str) -> list:\n",
        "    \"\"\"Fetch search results from Wikipedia API.\"\"\"\n",
        "    url = f\"https://fa.wikipedia.org/w/api.php?action=opensearch&format=json&formatversion=2&search={query}&namespace=0&limit=10&origin=*\"\n",
        "    async with httpx.AsyncClient() as client:\n",
        "        response = await client.get(url, follow_redirects=True)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        return response.json()[1]\n",
        "    else:\n",
        "        print(f\"Error fetching search results: {response.status_code}\")\n",
        "        return []\n",
        "\n",
        "\n",
        "async def fetch_related_pages(title: str) -> list:\n",
        "    \"\"\"Fetch related pages from Wikipedia API.\"\"\"\n",
        "    url = f\"https://fa.wikipedia.org/api/rest_v1/page/related/{title}\"\n",
        "    async with httpx.AsyncClient() as client:\n",
        "        response = await client.get(url, follow_redirects=True)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        try:\n",
        "            related_pages = response.json().get(\"pages\", [])\n",
        "            return [page['title'] for page in related_pages]\n",
        "        except ValueError as e:\n",
        "            print(f\"Error parsing JSON for title {title}: {e}\")\n",
        "            return []\n",
        "    else:\n",
        "        print(f\"Error fetching related pages for {title}: {response.status_code}\")\n",
        "        return []\n",
        "\n",
        "\n",
        "async def build_graph(query: str, depth: int = 2) -> nx.Graph:\n",
        "    \"\"\"Create a graph from the Wikipedia API results.\"\"\"\n",
        "    graph = nx.Graph()\n",
        "    visited = set()\n",
        "\n",
        "    async def explore_related_pages(page: str, current_depth: int):\n",
        "        \"\"\"Recursively explore related pages and build the graph.\"\"\"\n",
        "        if current_depth > depth or page in visited:\n",
        "            return\n",
        "\n",
        "        visited.add(page)\n",
        "        graph.add_node(page.replace(\"_\", \" \"))  # Replace underscores with spaces\n",
        "\n",
        "        related_pages = await fetch_related_pages(page)\n",
        "        for related_page in related_pages:\n",
        "            graph.add_edge(page.replace(\"_\", \" \"), related_page.replace(\"_\", \" \"))\n",
        "            await explore_related_pages(related_page, current_depth + 1)\n",
        "\n",
        "    search_results = await fetch_search_results(query)\n",
        "    for page in search_results:\n",
        "        await explore_related_pages(page, 1)\n",
        "\n",
        "    return graph\n",
        "\n",
        "\n",
        "async def generate_interactive_graph(query: str, depth: int = 2):\n",
        "    \"\"\"Generate an interactive graph and save it to an HTML file and Excel.\"\"\"\n",
        "    graph = await build_graph(query, depth)\n",
        "\n",
        "    # Generate interactive graph\n",
        "    net = Network(height='750px', width='100%', bgcolor='#ffffff', font_color='black', notebook=False, cdn_resources=\"local\")\n",
        "    net.from_nx(graph)\n",
        "    net.write_html(\"wikipedia_graph.html\")\n",
        "    print(\"Interactive graph saved to 'wikipedia_graph.html'.\")\n",
        "\n",
        "    # Prepare data for Excel export\n",
        "    edges = list(graph.edges())\n",
        "    nodes = list(graph.nodes())\n",
        "\n",
        "    edges_df = pd.DataFrame(edges, columns=[\"Source\", \"Target\"])\n",
        "    nodes_df = pd.DataFrame({\"Node\": nodes})\n",
        "\n",
        "    # Generate a unique file path for saving\n",
        "    timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
        "    os.makedirs('export', exist_ok=True)\n",
        "    file_path = f'export/{query}-wikipedia_graph_{timestamp}.xlsx'\n",
        "\n",
        "    # Save data to Excel with separate sheets for nodes and edges\n",
        "    with pd.ExcelWriter(file_path) as writer:\n",
        "        nodes_df.to_excel(writer, sheet_name=\"Nodes\", index=False)\n",
        "        edges_df.to_excel(writer, sheet_name=\"Edges\", index=False)\n",
        "\n",
        "    print(f\"Graph data saved to '{file_path}'.\")\n",
        "    files.download(file_path)\n",
        "    files.download(\"wikipedia_graph.html\")\n",
        "\n",
        "# Example usage:\n",
        "query = \"بهینه‌سازی موتور جستجو\"\n",
        "depth = 2  # Search depth\n",
        "await generate_interactive_graph(query, depth)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "nksSHz7wE-oi",
        "outputId": "6b43917d-173b-49e6-e0fc-0ea6f8ef9d46"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Interactive graph saved to 'wikipedia_graph.html'.\n",
            "Graph data saved to 'export/بهینه‌سازی موتور جستجو-wikipedia_graph_2024-11-08_16-30-40.xlsx'.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_bbb6e589-237a-4503-950d-4cb3e5aca798\", \"\\u0628\\u0647\\u06cc\\u0646\\u0647\\u200c\\u0633\\u0627\\u0632\\u06cc \\u0645\\u0648\\u062a\\u0648\\u0631 \\u062c\\u0633\\u062a\\u062c\\u0648-wikipedia_graph_2024-11-08_16-30-40.xlsx\", 13684)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_79b27765-a08a-4b57-b6f1-69610fc03b67\", \"wikipedia_graph.html\", 96747)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKzhELHQCHYT"
      },
      "outputs": [],
      "source": []
    }
  ]
}