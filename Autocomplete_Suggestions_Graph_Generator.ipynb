{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMS66YH66u1CIFCT3eX2bfR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dadashzadeh/Keyword-Suggestion-Tool/blob/main/Autocomplete_Suggestions_Graph_Generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!!pip install httpx\n",
        "!!pip install pyvis\n",
        "!!pip install networkx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dE3zhPDQmlxW",
        "outputId": "e8490a19-d08e-4843-c97a-e053ebe35d52"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (3.4.2)']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import httpx\n",
        "from pyvis.network import Network\n",
        "import networkx as nx\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import os\n",
        "from google.colab import files\n"
      ],
      "metadata": {
        "id": "2AUPon_kmo12"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nWb8rVafmgvD"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Function to fetch autocomplete suggestions using Google’s public autocomplete API\n",
        "def search_autocomplete(query):\n",
        "    try:\n",
        "        url = f\"http://suggestqueries.google.com/complete/search?client=firefox&q={query}\"\n",
        "        with httpx.Client() as client:\n",
        "            response = client.get(url, timeout=5)\n",
        "            # Parse the response as a JSON object\n",
        "            suggestions = response.json()[1]  # The second element of the response contains the suggestions\n",
        "            return suggestions\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching autocomplete suggestions for {query}: {e}\")\n",
        "        return []\n",
        "\n",
        "# Function to recursively add suggestions to the graph\n",
        "def add_suggestions_to_graph(G, query, data, depth=2, current_depth=1):\n",
        "    if current_depth > depth:\n",
        "        return\n",
        "\n",
        "    # Fetch autocomplete suggestions for the current query\n",
        "    suggestions = search_autocomplete(query)\n",
        "    if not suggestions:  # Check if no suggestions were returned\n",
        "        return\n",
        "\n",
        "    # Add nodes and edges for each suggestion\n",
        "    for suggestion in suggestions:\n",
        "        if not G.has_node(suggestion):  # Avoid adding duplicate nodes\n",
        "            G.add_node(suggestion)\n",
        "        if not G.has_edge(query, suggestion):  # Avoid adding duplicate edges\n",
        "            G.add_edge(query, suggestion)\n",
        "\n",
        "        # Add to data collection for saving later (must append to the list)\n",
        "        data.append({\"Source\": query, \"Target\": suggestion, \"Depth\": current_depth})\n",
        "\n",
        "        # Recursively fetch suggestions for this suggestion (sub-suggestions)\n",
        "        add_suggestions_to_graph(G, suggestion, data, depth, current_depth + 1)\n",
        "\n",
        "# Main query to search for autocomplete suggestions\n",
        "query = \"سئو\"\n",
        "\n",
        "# Create a networkx graph\n",
        "G = nx.Graph()\n",
        "\n",
        "# Add the main query node\n",
        "G.add_node(query)\n",
        "\n",
        "# Initialize data collection as an empty list (IMPORTANT)\n",
        "data = []  # Ensure this is a list, not an integer\n",
        "\n",
        "# Add suggestions to the graph recursively up to the desired depth (e.g., depth=2)\n",
        "add_suggestions_to_graph(G, query, data, depth=3)\n",
        "\n",
        "# Ensure the graph is not empty\n",
        "if len(G.nodes) > 1:\n",
        "    # Create a pyvis Network instance\n",
        "    net = Network(height='750px', width='100%', bgcolor='#ffffff', font_color='black', notebook=False, cdn_resources=\"local\")\n",
        "\n",
        "    # Convert the NetworkX graph to Pyvis graph\n",
        "    net.from_nx(G)\n",
        "\n",
        "    # Generate and save the interactive graph as an HTML file\n",
        "    net.write_html(\"autocomplete_graph.html\")\n",
        "\n",
        "    # Create a pandas DataFrame from the collected data (edges)\n",
        "    edges_df = pd.DataFrame(data)\n",
        "\n",
        "    # Create a pandas DataFrame for the nodes\n",
        "    nodes_df = pd.DataFrame({\"Node\": list(G.nodes)})\n",
        "\n",
        "    curr_datetime = datetime.now().strftime('%Y-%m-%d%H-%M-%S')\n",
        "    splitted_path = os.path.splitext(f'{query}-.xlsx')\n",
        "    modified_xlsx_path = splitted_path[0] + curr_datetime + splitted_path[1]\n",
        "\n",
        "    # Save both nodes and edges to separate sheets in an Excel file\n",
        "    with pd.ExcelWriter(modified_xlsx_path) as writer:\n",
        "        nodes_df.to_excel(writer, sheet_name=\"Nodes\", index=False)\n",
        "        edges_df.to_excel(writer, sheet_name=\"Edges\", index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the generated file"
      ],
      "metadata": {
        "id": "joWlXYVGnbux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(modified_xlsx_path)\n",
        "files.download(\"autocomplete_graph.html\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "nGRDxGQ9nKgJ",
        "outputId": "6118df00-2f28-42af-96cf-716752f94fdf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4736a8d9-8619-4975-b123-66c194f8dcb4\", \"\\u0633\\u0626\\u0648-2024-11-0802-32-24.xlsx\", 18348)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2cd831a1-742e-4a7b-8d2d-e2690716e17d\", \"autocomplete_graph.html\", 130061)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}